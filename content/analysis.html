---
title: "Analysis"
description: null
toc: yes
output:
html_document:
df_print: paged
featuredImage: https://upload.wikimedia.org/wikipedia/commons/7/77/Pebbleswithquarzite.jpg
draft: no
featuredVideo: null
---

<script src="/rmarkdown-libs/htmlwidgets/htmlwidgets.js"></script>
<link href="/rmarkdown-libs/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="/rmarkdown-libs/datatables-binding/datatables.js"></script>
<script src="/rmarkdown-libs/jquery/jquery-3.6.0.min.js"></script>
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="/rmarkdown-libs/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="/rmarkdown-libs/dt-core/js/jquery.dataTables.min.js"></script>
<link href="/rmarkdown-libs/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="/rmarkdown-libs/crosstalk/js/crosstalk.min.js"></script>

<div id="TOC">

</div>

<p>This comes from the file <code>content/analysis.Rmd</code>.</p>
<p>We describe here our detailed data analysis.</p>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ──
## ✔ ggplot2 3.3.6      ✔ purrr   0.3.4 
## ✔ tibble  3.1.8      ✔ dplyr   1.0.10
## ✔ tidyr   1.2.1      ✔ stringr 1.4.1 
## ✔ readr   2.1.2      ✔ forcats 0.5.2 
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>print(getwd())</code></pre>
<pre><code>## [1] &quot;/Users/xingru/MA415/ma4615-fa22-final-project-ma415_4444/content&quot;</code></pre>
<pre class="r"><code>load(here::here(&quot;dataset-ignore/clean_wage.RData&quot;))
load(here::here(&quot;dataset/wage_data_clean2.RData&quot;))
print(ls())</code></pre>
<pre><code>## [1] &quot;clean_wage&quot;       &quot;wage_data_clean2&quot;</code></pre>
<div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>As senior students, we often question ourselves about what we are doing right now. What those 22 years of education could bring us in the future? Money? Fame? We want to be rich but we don’t know if all those years of hard-work could lead to a rich life. Therefore, we want to explore the relationship between wage and education.</p>
<p>We also noticed that sexism is a huge issue in society, especially when it comes to wage. So we are also interested in the factors that result in the wage difference in terms of gender.</p>
<p>Along the way of exploration, we discovered some interesting variables that may also influence the wage. So we’re going to build models to predict wages based on those variables.</p>
</div>
<div id="breadth-and-depth-of-data-analysis" class="section level2">
<h2>Breadth and depth of data analysis</h2>
<p>We are interested in the relationship between wage and variables including education, sex, age, family size, weeks worked last year, English-speaking ability, marital status, ownership of bathtub or shower, and region.</p>
<p>The questions are trying to answer are:
1. What factors are significant to predict one’s wage?
2. How does gender influence the performance of some variables toward wage?</p>
</div>
<div id="correlation-matrix" class="section level2">
<h2>correlation matrix</h2>
<p>We ran a Correlation Matrix to see if there are any highly correlated variables. OWNERSHIP ~ SHOWER caught our eyes so we decided to drop SHOWER because the correlation rate of “shower” and other variables are quite high.</p>
<pre class="r"><code>install.packages(&quot;GGally&quot;,repos = &quot;http://cran.us.r-project.org&quot;)</code></pre>
<pre><code>## 
## The downloaded binary packages are in
##  /var/folders/9z/nrpvh_xs1cj431xjx48zfgdc0000gn/T//RtmpWd4iaQ/downloaded_packages</code></pre>
<pre class="r"><code>library(GGally)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;GGally&#39;:
##   method from   
##   +.gg   ggplot2</code></pre>
<pre class="r"><code>wage_data_clean2 %&gt;%
ggcorr(method = c(&quot;everything&quot;, &quot;pearson&quot;)) </code></pre>
<pre><code>## Warning in ggcorr(., method = c(&quot;everything&quot;, &quot;pearson&quot;)): data in column(s)
## &#39;SPEAKENG&#39; are not numeric and were ignored</code></pre>
<p><img src="/analysis_files/figure-html/correlation%20matrix-1.png" width="672" /></p>
</div>
<div id="full-model" class="section level2">
<h2>Full Model</h2>
<p>We aim to build a model that can be used to predict wage. The independent variables we are interested in are education, sex, age, family size, weeks worked last year, english-speaking ability, marital status, ownership of bathtub or shower, and region.</p>
<div id="raw-model" class="section level3">
<h3>Raw Model</h3>
<p>We run the model1 with all variables above included.</p>
<pre class="r"><code>library(tidyverse)
lm_mod1 &lt;-lm(INCWAGE ~ EDUC.f + SEX.f + MARST.f + SPEAKENG.f + STATE.f + FAMSIZE + WKSWORK1 + AGE, data = clean_wage)

broom::tidy(lm_mod1) %&gt;%
  dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(., 5))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-1" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22","23","24","25","26","27","28","29","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66"],["(Intercept)","EDUC.f1","EDUC.f2","EDUC.f3","EDUC.f4","EDUC.f5","EDUC.f6","EDUC.f7","EDUC.f8","EDUC.f10","EDUC.f11","SEX.f2","MARST.f1","SPEAKENG.f1","SPEAKENG.f2","STATE.fAlaska","STATE.fArkansas","STATE.fCalifornia","STATE.fColorado","STATE.fDelaware","STATE.fDistrict of Columbia","STATE.fFlorida","STATE.fGeorgia","STATE.fHawaii","STATE.fIdaho","STATE.fIllinois","STATE.fIndiana","STATE.fIowa","STATE.fKansas","STATE.fKentucky","STATE.fLouisiana","STATE.fMaine","STATE.fMaryland","STATE.fMassachusetts","STATE.fMichigan","STATE.fMinnesota","STATE.fMississippi","STATE.fMissouri","STATE.fMontana","STATE.fNebraska","STATE.fNevada","STATE.fNew Hampshire","STATE.fNew Jersey","STATE.fNew Mexico","STATE.fNew York","STATE.fNorth Carolina","STATE.fNorth Dakota","STATE.fOhio","STATE.fOklahoma","STATE.fOregon","STATE.fPennsylvania","STATE.fRhode Island","STATE.fSouth Carolina","STATE.fSouth Dakota","STATE.fTennessee","STATE.fTexas","STATE.fUtah","STATE.fVermont","STATE.fVirginia","STATE.fWashington","STATE.fWest Virginia","STATE.fWisconsin","STATE.fWyoming","FAMSIZE","WKSWORK1","AGE"],[-6945.51652,124.5173,-378.82878,-102.74321,-153.70783,-1416.68995,5.82689,907.84996,4035.61829,9023.81553,12667.80683,-4025.90417,4141.8686,3703.13576,-1145.35648,3661.20425,790.12744,-623.65601,1756.4079,1372.87472,2924.20072,1113.01641,509.67825,1204.54741,-1316.91743,2020.98892,752.00204,78.1696,-1081.59537,290.02594,693.74593,-666.05498,3977.78928,3504.74131,1012.99997,1180.23578,-802.365,52.44238,-2607.7211,-555.99435,1672.07332,1604.13311,3450.95782,-376.11054,2762.61416,-60.836,-1125.17005,1049.0683,-647.61092,863.89301,1463.94084,2823.52873,-315.29652,-1864.13381,-220.74259,553.76601,-137.37128,-250.46663,1930.16134,2854.20323,552.23562,922.26839,1323.97334,-140.2729,779.50571,10.7398],[0,0.60245,0.00863,0.51351,0.27579,0,0.95895,0,0,0,0,0,0,0,0,0,0,0.00039,0,0,0,3e-05,0.00025,0,0,0,0,0.62937,0,0.06129,2e-05,0.00204,0,0,0,0,2e-05,0.71179,0,0.00363,0,0,0,0.06429,0,0.65158,4e-05,0,4e-05,0,0,0,0.04418,0,0.12906,0,0.42242,0.38314,0,0,0.00829,0,4e-05,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>By looking at the p-value from model1, we decided to drop ‘state’ and run the regression model again. The p-value of some categories of ‘state’ are greater than 0.05 so we would analyze this single variable later.
Education 01 (nursery school to grade 4) p-value &gt; 0.05 but we keep it because the p-values of other categories (of education) are smaller than 0.05.</p>
<div id="backward-stepwise-regression" class="section level4">
<h4>BACKWARD STEPWISE REGRESSION</h4>
<p>We ran a BACKWARD STEPWISE REGRESSION and figured that all the variables are significant in our model.</p>
<pre class="r"><code>library(MASS)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>backward &lt;- step(lm_mod1, direction = &quot;backward&quot;, scope = formula(lm_mod1), trace = 0)
backward$anova</code></pre>
<pre><code>##   Step Df Deviance Resid. Df   Resid. Dev      AIC
## 1      NA       NA   1961612 7.416385e+14 38744395</code></pre>
<pre class="r"><code>backward$coefficients</code></pre>
<pre><code>##                 (Intercept)                     EDUC.f1 
##                -6945.516516                  124.517299 
##                     EDUC.f2                     EDUC.f3 
##                 -378.828783                 -102.743211 
##                     EDUC.f4                     EDUC.f5 
##                 -153.707832                -1416.689955 
##                     EDUC.f6                     EDUC.f7 
##                    5.826888                  907.849961 
##                     EDUC.f8                    EDUC.f10 
##                 4035.618291                 9023.815529 
##                    EDUC.f11                      SEX.f2 
##                12667.806835                -4025.904166 
##                    MARST.f1                 SPEAKENG.f1 
##                 4141.868601                 3703.135757 
##                 SPEAKENG.f2               STATE.fAlaska 
##                -1145.356481                 3661.204255 
##             STATE.fArkansas           STATE.fCalifornia 
##                  790.127442                 -623.656009 
##             STATE.fColorado             STATE.fDelaware 
##                 1756.407900                 1372.874723 
## STATE.fDistrict of Columbia              STATE.fFlorida 
##                 2924.200716                 1113.016410 
##              STATE.fGeorgia               STATE.fHawaii 
##                  509.678255                 1204.547410 
##                STATE.fIdaho             STATE.fIllinois 
##                -1316.917433                 2020.988924 
##              STATE.fIndiana                 STATE.fIowa 
##                  752.002042                   78.169599 
##               STATE.fKansas             STATE.fKentucky 
##                -1081.595370                  290.025937 
##            STATE.fLouisiana                STATE.fMaine 
##                  693.745926                 -666.054980 
##             STATE.fMaryland        STATE.fMassachusetts 
##                 3977.789279                 3504.741308 
##             STATE.fMichigan            STATE.fMinnesota 
##                 1012.999966                 1180.235784 
##          STATE.fMississippi             STATE.fMissouri 
##                 -802.364997                   52.442383 
##              STATE.fMontana             STATE.fNebraska 
##                -2607.721105                 -555.994352 
##               STATE.fNevada        STATE.fNew Hampshire 
##                 1672.073321                 1604.133108 
##           STATE.fNew Jersey           STATE.fNew Mexico 
##                 3450.957819                 -376.110537 
##             STATE.fNew York       STATE.fNorth Carolina 
##                 2762.614159                  -60.836000 
##         STATE.fNorth Dakota                 STATE.fOhio 
##                -1125.170048                 1049.068302 
##             STATE.fOklahoma               STATE.fOregon 
##                 -647.610923                  863.893008 
##         STATE.fPennsylvania         STATE.fRhode Island 
##                 1463.940839                 2823.528730 
##       STATE.fSouth Carolina         STATE.fSouth Dakota 
##                 -315.296523                -1864.133810 
##            STATE.fTennessee                STATE.fTexas 
##                 -220.742590                  553.766010 
##                 STATE.fUtah              STATE.fVermont 
##                 -137.371277                 -250.466627 
##             STATE.fVirginia           STATE.fWashington 
##                 1930.161342                 2854.203228 
##        STATE.fWest Virginia            STATE.fWisconsin 
##                  552.235621                  922.268392 
##              STATE.fWyoming                     FAMSIZE 
##                 1323.973343                 -140.272905 
##                    WKSWORK1                         AGE 
##                  779.505714                   10.739804</code></pre>
<pre class="r"><code>summary(backward)</code></pre>
<pre><code>## 
## Call:
## lm(formula = INCWAGE ~ EDUC.f + SEX.f + MARST.f + SPEAKENG.f + 
##     STATE.f + FAMSIZE + WKSWORK1 + AGE, data = clean_wage)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -58765  -9926    147   6134 110544 
## 
## Coefficients:
##                               Estimate Std. Error  t value Pr(&gt;|t|)    
## (Intercept)                 -6945.5165   213.0137  -32.606  &lt; 2e-16 ***
## EDUC.f1                       124.5173   239.0540    0.521 0.602454    
## EDUC.f2                      -378.8288   144.2343   -2.626 0.008627 ** 
## EDUC.f3                      -102.7432   157.2472   -0.653 0.513507    
## EDUC.f4                      -153.7078   141.0391   -1.090 0.275791    
## EDUC.f5                     -1416.6900   136.1889  -10.402  &lt; 2e-16 ***
## EDUC.f6                         5.8269   113.2005    0.051 0.958948    
## EDUC.f7                       907.8500   117.1264    7.751 9.12e-15 ***
## EDUC.f8                      4035.6183   121.5552   33.200  &lt; 2e-16 ***
## EDUC.f10                     9023.8155   116.3784   77.539  &lt; 2e-16 ***
## EDUC.f11                    12667.8068   119.8462  105.701  &lt; 2e-16 ***
## SEX.f2                      -4025.9042    28.0488 -143.532  &lt; 2e-16 ***
## MARST.f1                     4141.8686    31.4800  131.572  &lt; 2e-16 ***
## SPEAKENG.f1                  3703.1358   148.1734   24.992  &lt; 2e-16 ***
## SPEAKENG.f2                 -1145.3565   167.8706   -6.823 8.93e-12 ***
## STATE.fAlaska                3661.2043   301.7606   12.133  &lt; 2e-16 ***
## STATE.fArkansas               790.1274   144.4832    5.469 4.54e-08 ***
## STATE.fCalifornia            -623.6560   175.8286   -3.547 0.000390 ***
## STATE.fColorado              1756.4079   116.7607   15.043  &lt; 2e-16 ***
## STATE.fDelaware              1372.8747   148.8690    9.222  &lt; 2e-16 ***
## STATE.fDistrict of Columbia  2924.2007   169.8315   17.218  &lt; 2e-16 ***
## STATE.fFlorida               1113.0164   265.9238    4.185 2.85e-05 ***
## STATE.fGeorgia                509.6783   139.3016    3.659 0.000253 ***
## STATE.fHawaii                1204.5474   210.2638    5.729 1.01e-08 ***
## STATE.fIdaho                -1316.9174   208.7965   -6.307 2.84e-10 ***
## STATE.fIllinois              2020.9889   126.8088   15.937  &lt; 2e-16 ***
## STATE.fIndiana                752.0020   142.1998    5.288 1.23e-07 ***
## STATE.fIowa                    78.1696   161.9713    0.483 0.629370    
## STATE.fKansas               -1081.5954   167.9763   -6.439 1.20e-10 ***
## STATE.fKentucky               290.0259   154.9760    1.871 0.061286 .  
## STATE.fLouisiana              693.7459   164.2099    4.225 2.39e-05 ***
## STATE.fMaine                 -666.0550   215.8995   -3.085 0.002035 ** 
## STATE.fMaryland              3977.7893   148.9146   26.712  &lt; 2e-16 ***
## STATE.fMassachusetts         3504.7413   144.0621   24.328  &lt; 2e-16 ***
## STATE.fMichigan              1013.0000   128.9250    7.857 3.93e-15 ***
## STATE.fMinnesota             1180.2358   143.3513    8.233  &lt; 2e-16 ***
## STATE.fMississippi           -802.3650   186.4806   -4.303 1.69e-05 ***
## STATE.fMissouri                52.4424   141.9479    0.369 0.711794    
## STATE.fMontana              -2607.7211   237.0016  -11.003  &lt; 2e-16 ***
## STATE.fNebraska              -555.9944   191.1375   -2.909 0.003627 ** 
## STATE.fNevada                1672.0733   180.3320    9.272  &lt; 2e-16 ***
## STATE.fNew Hampshire         1604.1331   222.3028    7.216 5.36e-13 ***
## STATE.fNew Jersey            3450.9578   138.4766   24.921  &lt; 2e-16 ***
## STATE.fNew Mexico            -376.1105   203.2872   -1.850 0.064293 .  
## STATE.fNew York              2762.6142   121.9627   22.651  &lt; 2e-16 ***
## STATE.fNorth Carolina         -60.8360   134.7205   -0.452 0.651577    
## STATE.fNorth Dakota         -1125.1700   272.2767   -4.132 3.59e-05 ***
## STATE.fOhio                  1049.0683   128.5415    8.161 3.32e-16 ***
## STATE.fOklahoma              -647.6109   156.6946   -4.133 3.58e-05 ***
## STATE.fOregon                 863.8930   160.4576    5.384 7.29e-08 ***
## STATE.fPennsylvania          1463.9408   124.6108   11.748  &lt; 2e-16 ***
## STATE.fRhode Island          2823.5287   263.3910   10.720  &lt; 2e-16 ***
## STATE.fSouth Carolina        -315.2965   156.6779   -2.012 0.044179 *  
## STATE.fSouth Dakota         -1864.1338   256.7654   -7.260 3.87e-13 ***
## STATE.fTennessee             -220.7426   145.4340   -1.518 0.129060    
## STATE.fTexas                  553.7660   121.2774    4.566 4.97e-06 ***
## STATE.fUtah                  -137.3713   171.2385   -0.802 0.422425    
## STATE.fVermont               -250.4666   287.1888   -0.872 0.383136    
## STATE.fVirginia              1930.1613   138.6348   13.923  &lt; 2e-16 ***
## STATE.fWashington            2854.2032   139.8901   20.403  &lt; 2e-16 ***
## STATE.fWest Virginia          552.2356   209.1676    2.640 0.008287 ** 
## STATE.fWisconsin              922.2684   140.7126    6.554 5.59e-11 ***
## STATE.fWyoming               1323.9733   323.3743    4.094 4.24e-05 ***
## FAMSIZE                      -140.2729     9.6447  -14.544  &lt; 2e-16 ***
## WKSWORK1                      779.5057     0.6268 1243.540  &lt; 2e-16 ***
## AGE                            10.7398     0.8299   12.941  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19440 on 1961612 degrees of freedom
## Multiple R-squared:  0.5389, Adjusted R-squared:  0.5389 
## F-statistic: 3.527e+04 on 65 and 1961612 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<div id="final-model" class="section level3">
<h3>Final Model</h3>
<pre class="r"><code>suppressPackageStartupMessages(library(tidyverse))
lm_mod2 &lt;-lm(INCWAGE ~ EDUC.f + SEX.f + MARST.f + SPEAKENG.f + FAMSIZE + WKSWORK1 + AGE, data = clean_wage)

broom::tidy(lm_mod2) %&gt;%
   dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(., 5))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-2" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18"],["(Intercept)","EDUC.f1","EDUC.f2","EDUC.f3","EDUC.f4","EDUC.f5","EDUC.f6","EDUC.f7","EDUC.f8","EDUC.f10","EDUC.f11","SEX.f2","MARST.f1","SPEAKENG.f1","SPEAKENG.f2","FAMSIZE","WKSWORK1","AGE"],[-5188.19344,47.75425,-584.54807,-412.00515,-419.87711,-1609.61399,-134.78738,777.81095,3944.80746,9068.54601,12828.5853,-4024.02508,4001.06459,3208.25281,-1127.48856,-106.62647,778.89997,10.69349],[0,0.84194,5e-05,0.00887,0.00294,0,0.23423,0,0,0,0,0,0,0,0,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Interpretation based on coefficients:
Education: there’s a turning point at grade 12 (06), negative relationship before grade 12, then positive relationship after grade 12.
Gender: the average wage of females is $4121 lower than males per year.
Marriage status: marriage’s wage is $3870 higher than non-marriage per year.
English speaking: dummy variable error
Family size: negative relationship $-279 per year
Weeks work last year: positive relationship $773 per year</p>
</div>
<div id="coefficient-breakdown" class="section level3">
<h3>Coefficient Breakdown</h3>
<div id="wage-education" class="section level4">
<h4>wage ~ education</h4>
<pre class="r"><code>suppressPackageStartupMessages(library(tidyverse))
lm_mod3 &lt;-lm(INCWAGE ~ EDUC.f, data = clean_wage)

broom::tidy(lm_mod3) %&gt;%
   dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(., 5))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-3" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11"],["(Intercept)","EDUC.f1","EDUC.f2","EDUC.f3","EDUC.f4","EDUC.f5","EDUC.f6","EDUC.f7","EDUC.f8","EDUC.f10","EDUC.f11"],[10779.76645,-1188.60116,-1430.49846,-3318.01018,-5414.4705,-4884.61831,5640.53847,8605.34586,16010.02586,21737.0139,24596.18779],[0,0.00037,0,0,0,0,0,0,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>#relationship between wage and education
clean_wage %&gt;%
ggplot(aes(x = as.factor(EDUC), y = INCWAGE)) + geom_boxplot()</code></pre>
<p><img src="/analysis_files/figure-html/variable:%20EDUC%20%20graph-1.png" width="672" />
We noticed that at first, as the year of education increase, the wage is lower comparing with no schooling. However, since</p>
<div id="wage-education-by-sex" class="section level5">
<h5>wage ~ education (by sex)</h5>
<pre class="r"><code>#relationship between wage and education colored by gender

library(ggplot2)
library(tidyr)
clean_wage %&gt;% 
  ggplot(aes(x = as.factor(EDUC), y = INCWAGE, color=as.factor(SEX))) + geom_boxplot(outlier.shape = NA)</code></pre>
<p><img src="/analysis_files/figure-html/variable:%20EDUC%20+%20gender-1.png" width="672" /></p>
<pre class="r"><code>edu_gd &lt;- lm(INCWAGE ~ EDUC.f + SEX.f + EDUC.f*SEX.f, data = clean_wage)

broom::tidy(edu_gd) %&gt;%
   dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(., 5))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-4" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-4">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","16","17","18","19","20","21","22"],["(Intercept)","EDUC.f1","EDUC.f2","EDUC.f3","EDUC.f4","EDUC.f5","EDUC.f6","EDUC.f7","EDUC.f8","EDUC.f10","EDUC.f11","SEX.f2","EDUC.f1:SEX.f2","EDUC.f2:SEX.f2","EDUC.f3:SEX.f2","EDUC.f4:SEX.f2","EDUC.f5:SEX.f2","EDUC.f6:SEX.f2","EDUC.f7:SEX.f2","EDUC.f8:SEX.f2","EDUC.f10:SEX.f2","EDUC.f11:SEX.f2"],[14047.3088,-627.20574,-831.70461,-4491.73392,-7145.2102,-6622.55672,6744.8904,9450.75514,17891.2605,22752.53668,21149.04062,-6661.84725,-860.46683,-1387.8265,1836.79235,3276.14116,3347.11621,-2210.18267,-1223.65128,-2335.7633,-939.19253,6971.65332],[0,0.18234,0.00287,0,0,0,0,0,0,0,0,0,0.19347,0.00052,2e-05,0,0,0,0.00011,0,0.0028,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>par(mfrow = c(2, 2))
plot(lm_mod3)</code></pre>
<p><img src="/analysis_files/figure-html/QQ-1.png" width="672" /></p>
<pre class="r"><code>male_data &lt;- clean_wage %&gt;%
  filter(SEX==1)

female_data &lt;- clean_wage %&gt;%
  filter(SEX==2)</code></pre>
<pre class="r"><code>suppressPackageStartupMessages(library(tidyverse))
lm_educ_male &lt;-lm(INCWAGE ~ as.factor(EDUC), data = male_data)

broom::tidy(lm_educ_male) %&gt;%
  dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(.,))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-5" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-5">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11"],["(Intercept)","as.factor(EDUC)1","as.factor(EDUC)2","as.factor(EDUC)3","as.factor(EDUC)4","as.factor(EDUC)5","as.factor(EDUC)6","as.factor(EDUC)7","as.factor(EDUC)8","as.factor(EDUC)10","as.factor(EDUC)11"],[14047,-627,-832,-4492,-7145,-6623,6745,9451,17891,22753,21149],[0,0,0,0,0,0,0,0,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>suppressPackageStartupMessages(library(tidyverse))
lm_educ_female &lt;-lm(INCWAGE ~ as.factor(EDUC), data = female_data)

broom::tidy(lm_educ_female) %&gt;%
   dplyr::select(term, estimate, p.value) %&gt;% 
  mutate(across(where(is.numeric), ~round(.,))) %&gt;% 
  DT::datatable()</code></pre>
<div id="htmlwidget-6" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-6">{"x":{"filter":"none","vertical":false,"data":[["1","2","3","4","5","6","7","8","9","10","11"],["(Intercept)","as.factor(EDUC)1","as.factor(EDUC)2","as.factor(EDUC)3","as.factor(EDUC)4","as.factor(EDUC)5","as.factor(EDUC)6","as.factor(EDUC)7","as.factor(EDUC)8","as.factor(EDUC)10","as.factor(EDUC)11"],[7385,-1488,-2220,-2655,-3869,-3275,4535,8227,15555,21813,28121],[0,0,0,0,0,0,0,0,0,0,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>term<\/th>\n      <th>estimate<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"className":"dt-right","targets":[2,3]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<div id="wage-age-by-sex" class="section level4">
<h4>wage ~ age (by sex)</h4>
<pre class="r"><code>#relationship between wage and education colored by gender
clean_wage %&gt;%
ggplot(aes(x = AGE*AGE, y = INCWAGE, color=as.factor(SEX))) + geom_smooth()</code></pre>
<pre><code>## `geom_smooth()` using method = &#39;gam&#39; and formula &#39;y ~ s(x, bs = &quot;cs&quot;)&#39;</code></pre>
<p><img src="/analysis_files/figure-html/q1.2.2-1.png" width="672" /></p>
</div>
<div id="wage-marital-status-by-sex" class="section level4">
<h4>wage ~ marital status (by sex)</h4>
<pre class="r"><code>clean_wage %&gt;%
ggplot(aes(x = as.factor(MARST), y = INCWAGE, color=as.factor(SEX))) + geom_boxplot()</code></pre>
<p><img src="/analysis_files/figure-html/MARST-1.png" width="672" /></p>
<hr />
</div>
</div>
</div>
<div id="note-on-attribution" class="section level2">
<h2>Note on Attribution</h2>
<p>If you are directly quoting from a source, please make that clear. You can show quotes using <code>&gt;</code> like this</p>
<pre><code>&gt; To be or not to be.</code></pre>
<blockquote>
<p>To be or not to be.</p>
</blockquote>
<p>Also, make sure to provide a link or citation to where you are quoting from.</p>
<hr />
</div>
<div id="rubric-on-this-page" class="section level2">
<h2>Rubric: On this page</h2>
<p>you will</p>
<ul>
<li>Introduce what motivates your Data Analysis (DA)
<ul>
<li>Which variables and relationships are you most interested in?</li>
</ul></li>
</ul>
<pre class="r"><code>#the relationship between wage and education.
#what factors can influence one&#39;s wage and salary</code></pre>
<ul>
<li>What questions are you interested in answering?</li>
</ul>
<pre class="r"><code>#relationship between wage and education</code></pre>
<ul>
<li>Breadth of the DA
<ul>
<li>Make sure that you ask enough initial questions to explore the different variables in your data.</li>
<li>i.e. Do you explore more than just one or two variables? Do you explore a few different relationships or many?</li>
</ul></li>
</ul>
<pre class="r"><code>#relationship between wage and education colored by gender</code></pre>
<ul>
<li><p>Depth of the DA</p>
<ul>
<li>When you answer one question, usually more questions arise as well.</li>
<li>The depth of the DA is about coming up with and exploring the answers to these questions, often iterating the process a few times.</li>
</ul></li>
<li><p>Modeling and Inference</p>
<ul>
<li><p>You should also include some kind of formal statistical model and/or inference. This could be a linear regression, logistic regression, hypothesis testing etc.</p></li>
<li><p>Explain the techniques you used for validating your results.</p></li>
<li><p>Describe the results of your modelling and make sure to give a sense of the uncertainty in your estimates and conclusions.</p></li>
</ul></li>
<li><p>Explain the flaws and limitations of your analysis</p>
<ul>
<li>Are there some assumptions that you needed to make that might not hold? Is there other data that would help to answer your questions? …</li>
</ul></li>
<li><p>Clarity Figures</p>
<ul>
<li>Are your figures/tables/results easy to read, informative, without problems like overplotting, hard-to-read labels, etc?</li>
<li>Each figure should provide a key insight. Too many figures or other data summaries can detract from this.</li>
</ul></li>
<li><p>Clarity of Explanations</p>
<ul>
<li>Do you introduce why you are doing each analysis?</li>
<li>How well do you explain each figure/result?</li>
<li>Do you provide interpretations that suggest further analysis or explanations for observed phenomenon?</li>
</ul></li>
<li><p>Organization and cleanliness.</p>
<ul>
<li>Make sure to remove excessive warnings, use clean easy-to-read code, organize with sections or multiple pages, use bullets, etc.</li>
</ul></li>
</ul>
<p><strong>NOTE</strong>: Your Data Analysis can be broken up into multiple pages if that helps with your organization.</p>
</div>
